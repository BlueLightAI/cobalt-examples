{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHPXBBWLvmM7"
   },
   "source": [
    "## Intro\n",
    "\n",
    "At [BlueLightAI](https://bluelightai.com/) we are **thrilled** to help you identify the best model for your use case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk7x5BByvmM8"
   },
   "source": [
    "**What we do:**\n",
    "1. Our algorithm finds natural groups in your queries dataset üë•  ü§ù\n",
    "\n",
    "2. We illuminate their performance rates for model comparison üí° üìä\n",
    "\n",
    "Easily compare any pairs of models, like a base model üìç  \n",
    "\n",
    "and it's **fine-tuned Marqtune** checkpoint üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRp2uzI8vmM9"
   },
   "source": [
    "**In this notebook**: we compare the retrieval performance of a fine-tuned\n",
    "\n",
    "embeddding model and its base model on the ecommerce dataset\n",
    "\n",
    "(gs_100k_training.csv) provided in Marqtune's examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiSRp7jZvmM9"
   },
   "source": [
    "## Why are the results impactful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTemj_bmvmM9"
   },
   "source": [
    "**Going beyond average performance metrics**\n",
    "\n",
    "The average performance on your whole dataset is a good start but what about:\n",
    "- Low performing query types?\n",
    "- Query types that didn't improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnshPwQuvmM9"
   },
   "source": [
    "**Quickly Address** if your model is\n",
    "- Risky or ready to deploy based on real user queries\n",
    "- Needs more fine-tuning in Marqtune\n",
    "- Better or worse than another base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Sample setup steps to reproduce this specific notebook are in the cell below. To enable the most up-to-date version of Cobalt, see the Cobalt [Docs:](https://docs.cobalt.bluelightai.com/setup.html#installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the time of this writing, Python 3.12 was setup in a fresh virtual conda environment\n",
    "# in the terminal prior to installing cobalt:\n",
    "\n",
    "# conda create -y --name cobalt-env\n",
    "# conda activate cobalt-env\n",
    "# conda install -y python=3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you have not yet set up Cobalt and sentence_transformers.\n",
    "# The '%' is not needed if pip is run in the terminal.\n",
    "\n",
    "# %pip install cobalt-ai\n",
    "# %pip install sentence_transformers==3.3.1\n",
    "# 3.3.1 is the version of sentence_transformers used for this notebook at the time of writing\n",
    "\n",
    "# import cobalt\n",
    "# cobalt.register_license() #one time free trial registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MPFDXKlvmM-"
   },
   "source": [
    "**How:** We built a hierarchical clustering algorithm with roots in Topological Data Analysis.\n",
    "\n",
    "1. We take in unstructured data about your machine learning model (text, image, etc.)\n",
    "\n",
    "2. We embed it (or choose your own embedding like your use case specific embedding for ecommerce!)\n",
    "\n",
    "3. Our Algorithm outputs intuitive groups labels for your data as a dataframe.\n",
    "\n",
    "4. Easily compare performance across models using the groups on your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXYUIuK2vmM-"
   },
   "source": [
    "**In this notebook**, we use S-BERT to embed your text queries, but we handle any kind of embeddings!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHxq0Ko9vmM-"
   },
   "source": [
    "## Data Prep\n",
    "\n",
    "For each query we simple need a per sample performance rate\n",
    "- ie: for Search Retrieval it could be NDCG, Purchase rate, Clickthrough rate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r7iQ5XZzXLv"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cobalt\n",
    "from cobalt.embedding_models import SentenceTransformerEmbeddingModel\n",
    "from cobalt.lab.generate_interpretable_dataframe import get_interpretable_groups\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Qo76I_avmM-"
   },
   "source": [
    "In this notebook we precomputed these [NDCG](https://www.marqo.ai/blog/what-is-normalized-discounted-cumulative-gain-ndcg) performance rates using Marqo's data and tools.\n",
    "\n",
    "The predictions came from using **Marqtune** and **Marqo Cloud** Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkk-ju9QvmM_"
   },
   "source": [
    "Note: The \"Score\" per query has a best value of 1, and a worst value of 0 (NDCG metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "base_path = \"https://examples.cobalt.bluelightai.com/marqo-gs-10m/v1\"\n",
    "\n",
    "epoch_1_file = \"training_epoch_1_ndcg_per_query.csv\"\n",
    "epoch_14_file = \"training_epoch_14_ndcg_per_query.csv\"\n",
    "\n",
    "urlretrieve(f\"{base_path}/{epoch_1_file}\", epoch_1_file)\n",
    "urlretrieve(f\"{base_path}/{epoch_14_file}\", epoch_14_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "Lb69oh8130at",
    "outputId": "0c3653a3-f0a8-46db-c000-987f83df83bd"
   },
   "outputs": [],
   "source": [
    "epoch_14_ndcg_per_query_df = pd.read_csv(\"training_epoch_14_ndcg_per_query.csv\")\n",
    "epoch_14_ndcg_per_query_df = epoch_14_ndcg_per_query_df.drop(columns=[\"Score\"])\n",
    "epoch_14_ndcg_per_query_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "tdBx_QbR30at",
    "outputId": "d2a342cb-df25-40e3-fcc4-144a66a6bf25"
   },
   "outputs": [],
   "source": [
    "epoch_1_ndcg_per_query_df = pd.read_csv(\"training_epoch_1_ndcg_per_query.csv\")\n",
    "epoch_1_ndcg_per_query_df = epoch_1_ndcg_per_query_df.drop(\n",
    "    columns=[\"Unnamed: 0\", \"Score\"]\n",
    ")\n",
    "epoch_1_ndcg_per_query_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6mBbYLHvmM_"
   },
   "source": [
    "#### Data Prep: Compare Models on the same Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIQjgrRBvmM_"
   },
   "source": [
    "We can combine our dataframes since the queries are identical\n",
    "\n",
    "This allows us to see the scores for each model (ie: base epoch 1 vs. fine tune epoch 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jizt4BHFvmM_"
   },
   "outputs": [],
   "source": [
    "model_comparison_df = epoch_1_ndcg_per_query_df.copy()\n",
    "model_comparison_df = model_comparison_df.rename(\n",
    "    columns={\"ndcg_score\": \"score_epoch_1\"}\n",
    ")\n",
    "model_comparison_df[\"score_epoch_14\"] = epoch_14_ndcg_per_query_df[\"ndcg_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_ipjmf7vmNA"
   },
   "outputs": [],
   "source": [
    "model_comparison_df[\"fine_tuning_impact\"] = (\n",
    "    model_comparison_df[\"score_epoch_14\"] - model_comparison_df[\"score_epoch_1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JpzsbIwovmNA",
    "outputId": "0edde042-eb8b-4b1d-ee22-36b361817b5f"
   },
   "outputs": [],
   "source": [
    "model_comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp1nXnDqvmNA"
   },
   "source": [
    "We can see in the plot below\n",
    "- Many queries got worse from this fine-tuning run\n",
    "\n",
    "- And many queries had around the same performance\n",
    "\n",
    "Then we show you what groups of queries this is happening to üî¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "wfPH-1MPvmNA",
    "outputId": "3cc27f7a-c0b9-4c78-b5a7-c00691072a4f"
   },
   "outputs": [],
   "source": [
    "model_comparison_df[\"fine_tuning_impact\"].plot.hist(\n",
    "    title=\"Impact Per Query from Fine Tuning\",\n",
    "    xlabel=\"Raw Change NDCG from Fine Tuning\",\n",
    "    ylabel=\"Count\",\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlnH3ki8vmNA"
   },
   "source": [
    "#### And Now... üî•\n",
    "\n",
    "1. We compute intuitive group labels on your queries\n",
    "\n",
    "2. and illuminate their performance on each model üîé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "24f58b961c9044c7813fab881d1355da",
      "7571948bf1c94a6fa05b8d48a6019d1e",
      "e7a333ca01a24c5a82a4f2bb94d6a657",
      "e145d9693266468ca35961e6cb5ba3dc",
      "a373e70c66304675a3f4e6e5ec822aec",
      "6ef55a9e1aee4daca54696f95876b2c7",
      "3179e88b2c3c42b0996aa387d68ec804",
      "794e21f5b759441a9d9474985c95508d",
      "21516fdea0844de0839531bd9a108a96",
      "7f7d6ad825904baba69673d82b4ab892",
      "882c8c79066d4366b0d3ae81cebd50c9"
     ]
    },
    "id": "XnQIRsGCvmNA",
    "outputId": "8755626b-dc38-4970-ab22-3cae987ee512"
   },
   "outputs": [],
   "source": [
    "# First load your dataframe into a `CobaltDataset`.\n",
    "ds = cobalt.CobaltDataset(model_comparison_df)\n",
    "\n",
    "# In this case, embed your data with a specific version of SBERT.\n",
    "# You can embed your data with your choice of model.\n",
    "m = SentenceTransformerEmbeddingModel(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Using the embedding model above, embed your data. You can specify GPU-acceleration here.\n",
    "embedding = m.embed(model_comparison_df[\"query\"].tolist(), device=\"cpu\")\n",
    "\n",
    "# And add the embedding to the dataset, using the \"cosine\" similarity metric.\n",
    "ds.add_embedding_array(embedding, metric=\"cosine\", name=\"sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "Lh2R_4rFvmNA",
    "outputId": "002e0cd4-0448-4567-ef2e-a24a80314820"
   },
   "outputs": [],
   "source": [
    "results, workspace, keywords_per_level = get_interpretable_groups(\n",
    "    ds,\n",
    "    text_column_name=\"query\",\n",
    "    n_gram_range=\"up_to_bigrams\",\n",
    "    min_level=0,\n",
    "    max_level=20,\n",
    "    max_keywords=3,\n",
    "    return_intermediates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kU3MpT0vmNA"
   },
   "outputs": [],
   "source": [
    "graph = workspace.graphs[\"New Graph\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsHnfVc6vmNB"
   },
   "source": [
    "### Observing the Results  üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3G-iVhuvmNB"
   },
   "source": [
    "Note: \"Score\" a best value of 1, and a worst value of 0 (NDCG metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "714IC9cWvmNB"
   },
   "source": [
    "**Starting Small**: Some queries got worse from fine-tuning!\n",
    "\n",
    " (see negative impact going from epoch 1 to epoch 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mk-lQOFgvmNB",
    "outputId": "d78b5447-30ae-48cb-f60a-d13a3ff64df1"
   },
   "outputs": [],
   "source": [
    "results.sort_values(by=[\"fine_tuning_impact\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAIO5N29vmNB"
   },
   "source": [
    "#### Bigger Groups with the \"level\" column:\n",
    "\n",
    "- The higher values for the \"level\" column retrieve larger sized groups on your source data\n",
    "\n",
    "- Each level contains all of the unique points from the source, so combine levels with caution\n",
    "\n",
    "- Levels are a part of our clustering algorithm design to enable \"zoom\" levels on patterns in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyeXK-Y8vmNB"
   },
   "source": [
    "Easily navigate the clustering in the dataframe:\n",
    "- Filter the results by a minimum query_count\n",
    "- Sort for largest impact!\n",
    "- Etcetera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "CNxhOcDDvmNB",
    "outputId": "cfdee870-bcf3-4d71-8fa2-865d4f8236fb"
   },
   "outputs": [],
   "source": [
    "results[(results[\"level\"] == 10) & (results[\"query_count\"] > 10)].sort_values(\n",
    "    by=[\"fine_tuning_impact\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsuzSCs3vmNB"
   },
   "outputs": [],
   "source": [
    "from cobalt.lab.neighbors import get_raw_subset_with_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8nAjh8_vmNB"
   },
   "source": [
    "#### Inspecting the Original Samples for a group\n",
    "\n",
    "- For any \"Label\" you want to understand more about, pass it and its \"level\" column below (for uniqueness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ7wyrT6vmNB"
   },
   "outputs": [],
   "source": [
    "see_label = \"boys equestrian, equestrian boots, equestrian\"  # Insert Here\n",
    "level_column_for_see_label = (\n",
    "    10  # Make sure this matches your row of interest from the results dataframe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "_1DDeBbZvmNB",
    "outputId": "42b40e59-01ea-4ba6-ce7d-a3e1684ed3df"
   },
   "outputs": [],
   "source": [
    "results[results[\"Label\"] == see_label].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VyVJC-kvmNB"
   },
   "source": [
    "Simply run the next cell to see the matching source data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "kWoZUdA1vmNC",
    "outputId": "37248bb2-9902-4b77-eca2-a441323d0552"
   },
   "outputs": [],
   "source": [
    "raw_data = get_raw_subset_with_label(\n",
    "    coarseness=level_column_for_see_label,\n",
    "    label=see_label,\n",
    "    g=graph,\n",
    "    ds=ds,\n",
    "    keywords_per_level=keywords_per_level,\n",
    ")\n",
    "raw_data.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA4B-64YvmNH"
   },
   "source": [
    "#### Super Positive Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gE4GUctlvmNH"
   },
   "source": [
    "Fine Tuning with Marqtune had a huge positive impact of +0.29  for \"cellars, cellar, cellar temperature\" points\n",
    "\n",
    "Many individual queries went from 0 to hero! (close to max NDCG of 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnQFZpmUvmNH"
   },
   "source": [
    "**Note**: Some queries still have huge room for improvement\n",
    "\n",
    "ie: \"Freestanding cellars\" and \"Cellar Cooling\" still have a score of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUgLIL7ZvmNH"
   },
   "outputs": [],
   "source": [
    "see_label = \"cellars, cellar, cellar temperature\"  # Insert Here\n",
    "level_column_for_see_label = (\n",
    "    12  # Make sure this matches your row of interest from the results dataframe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "6rSP9xhUvmNH",
    "outputId": "19fb6d0f-ed51-411b-bddd-31604b599e9e"
   },
   "outputs": [],
   "source": [
    "results[\n",
    "    (results[\"Label\"] == see_label) & (results[\"level\"] == level_column_for_see_label)\n",
    "].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "8urw01rhvmNH",
    "outputId": "f7459f0d-bdfd-43b9-9716-c74e0cc977ba"
   },
   "outputs": [],
   "source": [
    "raw_data = get_raw_subset_with_label(\n",
    "    coarseness=level_column_for_see_label,\n",
    "    label=see_label,\n",
    "    g=graph,\n",
    "    ds=ds,\n",
    "    keywords_per_level=keywords_per_level,\n",
    ")\n",
    "raw_data.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "gHCAySxCvmNI",
    "outputId": "589c6b20-7944-45d9-a6e8-58c4844a3c42"
   },
   "outputs": [],
   "source": [
    "raw_data.df[raw_data.df[\"fine_tuning_impact\"] == 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah0Qy9JWvmNI"
   },
   "source": [
    "How to Improve your Model üí™\n",
    "- Try fine-tuning longer in Marqtune\n",
    "- Vary your fine-tuning hyperparameters\n",
    "- Compare to other base-models\n",
    "- Curate your training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHGvFL9GvmNI"
   },
   "source": [
    "Feel free to email support@bluelightai.com for enhancements üí™ or troubleshooting üôè"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21516fdea0844de0839531bd9a108a96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24f58b961c9044c7813fab881d1355da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7571948bf1c94a6fa05b8d48a6019d1e",
       "IPY_MODEL_e7a333ca01a24c5a82a4f2bb94d6a657",
       "IPY_MODEL_e145d9693266468ca35961e6cb5ba3dc"
      ],
      "layout": "IPY_MODEL_a373e70c66304675a3f4e6e5ec822aec"
     }
    },
    "3179e88b2c3c42b0996aa387d68ec804": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ef55a9e1aee4daca54696f95876b2c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7571948bf1c94a6fa05b8d48a6019d1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ef55a9e1aee4daca54696f95876b2c7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3179e88b2c3c42b0996aa387d68ec804",
      "value": "Batches:‚Äá100%"
     }
    },
    "794e21f5b759441a9d9474985c95508d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f7d6ad825904baba69673d82b4ab892": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "882c8c79066d4366b0d3ae81cebd50c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a373e70c66304675a3f4e6e5ec822aec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e145d9693266468ca35961e6cb5ba3dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f7d6ad825904baba69673d82b4ab892",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_882c8c79066d4366b0d3ae81cebd50c9",
      "value": "‚Äá886/886‚Äá[04:35&lt;00:00,‚Äá‚Äá5.46it/s]"
     }
    },
    "e7a333ca01a24c5a82a4f2bb94d6a657": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_794e21f5b759441a9d9474985c95508d",
      "max": 886,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_21516fdea0844de0839531bd9a108a96",
      "value": 886
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
